---
title: Achieving Photorealism With Neural Networks
date: 2021-05-31 09:00:00
tags:
    - Computer Vision
    - Technology

category: Technology 
keywords:
    - Computer Vision

mathjax: true
---


### Achieving Photorealism With Neural Networks
*Originally Published in [TowardsDataScience](https://towardsdatascience.com/achieving-photorealism-with-neural-networks-f80ded1b4cdb)*
#### Using synthetic data from GTA V

In the research world, especially while dealing with images, there appears to be
an increase of interest in using popular game environments, such as *Grand Theft
Auto (GTA), *for experimentation. With today’s high-quality graphics, these
environments produce synthetic images similar to real life, enabling researchers
to test their approaches to intricate problems such as [this one](http://Domain
Adaptation for Traffic Density Estimation), datasets for which are still
nascent.

![](https://cdn-images-1.medium.com/max/1800/1*LXLM7-sczg_v0ufScjwMVA.jpeg)
<span class="figcaption_hack">Photo by [Josue
Michel](https://unsplash.com/@josuemichelphotography?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
on
[Unsplash](https://unsplash.com/s/photos/camera-old?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)</span>

To further bridge this gap, there is a new work in town by [Vladlen
Koltun](http://vladlen.info/) and his team on making synthetic images more
lifelike, which they call: [Enhancing Photorealism
Enhancement](https://intel-isl.github.io/PhotorealismEnhancement/). We see the
use of GTA V cityscape to prove how the method could magically turn a video
snippet from the gameplay to a translation that looks as if captured with a dash
camera.

Let’s look at their results from the enhancer. The image below is a raw
synthetic one that is generated by the game. It does have that game-y synthetic
feel to it. This is the rendering obtained from the game engine without any
enhancers. While this can still be used as a testing ground for experiments it
does not guarantee the reproduction of results in real environments.

![](https://cdn-images-1.medium.com/max/1200/1*PccKm4aD6mHCpDBEuahpyg.png)
<span class="figcaption_hack">Raw Image From GTA V [1]</span>

Now let’s look at the one which is generated by the Enhancer’s flow. One could
easily confuse this for a real one. It does look a bit dull than the previous
one but a lot more realistic.

![](https://cdn-images-1.medium.com/max/1200/1*qEo150GXTx6RHsc9140bRw.jpeg)
<span class="figcaption_hack">Enhanced Image for Photorealism [1]</span>

It might look like a simple strategy at first, but there’s a lot to it, making
the work positively novel.

### **Behind The Scenes**

On a broad scale, this Enhancer is a Convolutional Neural Network (CNN) that
generates enhanced frames at required intervals. It then tries to translate the
raw frame to the style of [Cityscapes
Dataset](https://www.cityscapes-dataset.com/news/), which has a massive
collection of German cities recorded from a dash camera.

The interesting point is that the network doesn't just use the fully rendered
image (by the game engine) as input. Game engines produce something known as
G-Buffers, which are intermediate buffers that provide detailed information of
scenes such as geometry, materials, and lighting. As in the figure below, the
enhancement network uses these auxiliary inputs at multiple scales in addition
to the rendered images.

![](https://cdn-images-1.medium.com/max/1200/1*gzf11e7HXeheda-yg8hjVg.png)
<span class="figcaption_hack">Enhancement FLow [1]</span>

Before passing the G-buffer information to the Enhancement Network, there is an
additional Encoder network using which encoding is done. Both the networks are
trained using the [LPIPS loss,](https://ieeexplore.ieee.org/document/8578166)
which retains the structure of the rendered image and perceptual discrimination
to maximize the realism of the enhanced image.

Based on the input image, the network can add gloss to cars, smooth out the
roads and make other such alterations. The stability obtained with this approach
with almost no artifacts makes this new approach the best of all existing ones,
a comparison of which can be seen in the video below.

<span class="figcaption_hack">[Enhancing Photorealism
Enhancement](https://intel-isl.github.io/PhotorealismEnhancement/)</span>

### What’s Ahead

One of the painful points with research in Machine Vision is having a dataset
tailored to the problem statements. Due to the absence of quality datasets,
authors resort to standard ones, which might more often than not underrate or
underreport the work's potential. Strategies such as the one discussed above can
spark a new dimension where imitative datasets can be generated based on
requirements using simulation environments such as games. Before running any new
Vision-based self-driving algorithms on the field, it can be rapid-run on
simulations such as *enhanced *GTA V to find flaws and report results. So one
gets to speed up the testing and create the dataset you need, which is totally
awesome. Gear up for many such works in the near future!

*****

I hope you enjoyed reading this brief overview of E*nhancing Photorealism
Enhancement* by [Stephan Richter](http://www.stephanrichter.org/), [Hassan Abu
AlHaija](https://hassanhaija.github.io/), and [Vladlen
Koltun](http://vladlen.info/). If you are curious about the specifics of this
new strategy, do not forget to check out the [full
paper](http://vladlen.info/papers/EPE.pdf). To see more results of this work
with side-by-side comparisons, head out to this
[link](http://vladlen.info/papers/EPE.pdf).

[1] Richter, Stephan R., Hassan Abu AlHaija, and Vladlen Koltun. “Enhancing
Photorealism Enhancement.” *arXiv preprint arXiv:2105.04619* (2021)
